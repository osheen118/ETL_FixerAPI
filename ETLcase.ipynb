{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#from requests.structures import CaseInsensitiveDict\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import date, timedelta\n",
    "from datetime import date, timedelta\n",
    "import sqlite3 as sql\n",
    "import random\n",
    "from datetime import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1 \n",
    "<!--  Create function for : \n",
    "a. makes calls to fixerâ€™s API (https://fixer.io/documentation)\n",
    "b. fills a local SQlite database with currency information from 01.09.2018 to 30.09.2018. (Please use the default base currency, which is Euros) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for filling local SQlite database with currency information from 01.09.2018 to 30.09.2018.(base EUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_resp=  []\n",
    "def fetch_fixer(start_date,end_date):\n",
    "    delta = timedelta(days=1)\n",
    "    while start_date <= end_date:       # for fetching info for 01.09.2018 to 30.09.2018\n",
    "        temp_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "        url = \"http://data.fixer.io/api/\"+temp_date+\"?access_key=&base=EUR\"\n",
    "        \n",
    "        headers = CaseInsensitiveDict()\n",
    "        headers[\"Accept\"] = \"application/json\"\n",
    "        resp = requests.get(url, headers=headers)\n",
    "        json_resp.append(resp.json())\n",
    "        df = json_normalize(json_resp)   ## in a normalize way where indexing is based on the dates\n",
    "        resultdf = df.drop_duplicates()\n",
    "        start_date += delta\n",
    "    #print(resultdf)\n",
    "    conn = sql.connect(r'\\fixer.db')    # connecting to a db\n",
    "    resultdf.to_sql('Rates', conn,if_exists='replace', index=False) # table creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_fixer(date(2018, 9, 1),date(2018, 9, 30))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query execution\n",
    "conn = sql.connect(r'\\fixer.db')\n",
    "pd.read_sql('SELECT * FROM Rates', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2\n",
    "<!-- function which\n",
    "a. picks 5 random dates within the time period of 01.09.2018 and 30.09.2018.\n",
    "b. acquires the data via API calls and checks if the values are accurate\n",
    "c. throws an exception if they are not accurate -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that generates 5 random dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date(start, end,dates_temp):\n",
    "    n = 5\n",
    "    for i in range(n):\n",
    "        random_date = start + (end - start) * random.random()\n",
    "        dates_temp.append(random_date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving values for these 5 dates from the fixer API and then storing it in a db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_resp_temp=  []\n",
    "def accuracy_check(start_date,end_date):\n",
    "    dates_temp=[]\n",
    "    random_date(start_date, end_date,dates_temp)\n",
    "    for date in dates_temp:\n",
    "        print(date)\n",
    "        url = \"http://data.fixer.io/api/\"+date+\"?access_key=&base=EUR\"\n",
    "        headers = CaseInsensitiveDict()\n",
    "        headers[\"Accept\"] = \"application/json\"\n",
    "        resp = requests.get(url, headers=headers)\n",
    "        json_resp_temp.append(resp.json())\n",
    "        df_temp = json_normalize(json_resp_temp)\n",
    "        resultdf_temp = df_temp.drop_duplicates()\n",
    "    conn = sql.connect(r'\\fixer.db')\n",
    "    resultdf_temp.to_sql('Rates_temp', conn, if_exists='replace', index=False)\n",
    "    compare_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_date():\n",
    "    conn = sql.connect(r'\\fixer.db')\n",
    "    diff_rates=pd.read_sql('SELECT * FROM Rates_temp EXCEPT SELECT * FROM Rates', conn)\n",
    "    n=len(diff_rates)\n",
    "    if (n==0):\n",
    "        print (\"Values of respected dates are accurate\")\n",
    "    else:\n",
    "        print (\"There are some errors found for the specified dates\")\n",
    "        print (diff_rates['date'])\n",
    "        raise Exception(\"Found Errors!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_check(date(2018, 9, 1),date(2018, 9, 30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
